---
title: "R source code for loading LOS_model dataset from NHSRdatasets and its data dictionary"
author: "B213753"
date: "18/06/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Link to github repo

https://github.com/B213753/B213753_assessment.git

# Introduction

The data capture tool will look at the (length of stay) 'LOS_model' dataset and attempt to model hospital length of stay (LOS) in the ten different trusts within the dataset. Being able to analyse the differences, if any, in length of stay in different trusts will allow for better planning and allocation of resources, or perhaps highlight areas for improvement with future more in-depth analyses.

The tool will look to collect the following variables: patient ID, organisation, patient age, length of stay, and death. 
Please see the data dictionary below for more details on these variables.

### Outputs

The following files will be created/modified on successful conclusion of this script.
This script assumes the working directory is set as the root project directory.

- */RawData/LOS_raw.csv* - The raw LOS data containing 300 observations.
- */Data/LOS_train.csv* - The train dataset containing 288 observations.
- */Data/LOS_test.csv* - The test dataset containing 11 observations.
- */Data/LOS_test_marker.csv* - The test marker dataset containing 1 observation.
- */RawData/CollectedData_DataDictionary.csv* - The data dictionary created in R saved as csv.
- */RawData/complete_CollectedData.rds* - R dataset file containing the data dictionary and other metadata appended onto the collected dataset.


# Load packages and data

The following packages are required for this script:

- **NHSRdatasets** - the package containing the dataset selected (LOS_model) for this project.

- **tidyverse** - The tidyverse is a collection of R packages used in this script for most functions
in this script in the manipulation of data and files.

- **here** - Used for easy file referencing in project-oriented workflows.

- **knitr** - Used in this script to visualize tables using kable().

- **caret** - Used in this script for a function called createDataPartition() which
helped split the dataset into test and training sets.

- **dataMeta** - Used to create a data dictionary within R and append to a dataset.


```{r a,message = FALSE, warning = FALSE}
library(NHSRdatasets)
library(tidyverse)
library(here)
library(knitr)
library(caret)
library(dataMeta)
```

# Data Dictionary

#### See below for the R source code which builds and appends a dictionary in R to the collected dataset.

## Data use 

#### The data management plan is found in the Outputs folder of the repository.

The data collection tool will collect the following variables for use in statistical analyses and modelling: patient ID, organisation, patient age, length of stay, and death. 

The LOS_model is a synthetic dataset from the NHSRdatasets package in R. Data collected using the data collection tool is created during manual user inputs using the tool.

The dataset will undergo analysis, exploration and transformation using RStudio within the Author's Noteable enivronment.The dataset and its outputs will be used to analyse and model the length of stay (LOS) data for hospital admissions. The aim is to seek meaning relationships that aims to improve  health and social care resource allocation and delivery.

## Variable description

The collected dataset contains:

- **ID** : an integer value representing patient number - should be unique and allows referencing rows to the original raw data.
  + Quantitative data type. 
  + Min value: none
  + Max value: 99999
  + Allowed values: only integer values allowed. The tool does not check for unique IDs (allows data entry for duplicate ID). 
  + Example: 1, 43

- **Organisation** : a factor consisting of a string that represents a hospital or organisation e.g. "Trust1".
  + Fixed data type.
  + The LOS_model dataset contains 10 organisations labelled as:
    + "Trust1"
    + "Trust2"
    + "Trust3"
    + "Trust4"
    + "Trust5"
    + "Trust6"
    + "Trust7"
    + "Trust8"
    + "Trust9"
    + "Trust10"
  + Allowed values: the data tool only allows selection from the 10 organisations in the LOS_model dataset.

- **Age** : an integer value representing age of the patient.
  + Quantitative data type.
  + Min value: 0
  + Max value: 150
  + Allowed values: only integer values allowed.
  + Example: 45

- **LOS** : length of stay, an integer value representing the days a patient was in hospital.
  + Quantitative data type.
  + Min value: 0
  + Max value: None
  + Allowed values: only integer values allowed.
  + Example: 3

- **Death** : a factor consisting of a string that is either "Alive" or "Died", representing the status of the patient at the end of their hospital stay.
  + Fixed data type.
  + **Alive** : The patient survived the hospital admission.
  + **Died** : The patient died during hospital admission.
  + Allowed values: "Alive" or "Died.

- **consent** : a boolean value representing the consent from the end-user to process and share the data collected with the data capture tool.
  + Fixed data type.
  + **TRUE** : Consent granted by end-user.
  + **FALSE** : Consent not granted by end-user.
  + Allowed values: TRUE or FALSE.

## Dataset attributes

Relevant dataset attributes are below:

- **main** : string containing the main description of the dataset.
  + Simple attribute type

- **dictionary** : dataframe object containing the data dictionary.
  + Complex attribute type
  + **variable name** : string vector containing the name of each variable/column.
  + **variable description** : string vector containing the description of each variable/column.
  + **variable options** : string vector containing the data element options for each variable/column.
  + **notes** : string vector containing descriptions of variables and their options.

- **last_edit_date** : date format "YYYY-MM-DD HH:MM:SS" of the last time of edit of the dataset and attributes.
  + Simple attribute type

- **author** : string containing the name of the dataset and dictionary author. E.g. "B213753*
  + Simple attribute type



# Loading R dataset

## Loading raw data into R

The following code loads the raw LOS_model data from the NHSRdatasets package into
the R environment and assigns the data to a variable called LOS.

```{r load_data} 
data(LOS_model)
LOS <- LOS_model

```

## Dataset overview

Before getting the data ready for exploratory and statistical analyses, using glimpse()
and head(), the dataset was briefly explored for data types, and for any obvious anomalies.

- **ID** - *int* : ID values are of an integer class. This is acceptable as a row identifier and is used later for indexing.
- **Organisation** - *ord* : Organisation values is of an ordered factor class with 10 levels. This is acceptable for the data type it portrays.
- **Age** - *int* : Age values is of an integer class. This is acceptable for the data type it portrays.
- **LOS** - *int* : LOS (length of stay) values is of an integer class. This is acceptable for the data type it portrays.
- **Death** - *int* : Death values is of an integer class. Although statistical model software can work with binary 0/1 int values instead of factor, this variable is recoded into a factor with two levels for increased transparency and easier visualization (see below).

### Death Recode

```{r death_recode}
LOS <- LOS %>% 
  mutate(Death=recode(factor(Death),'1'='Died','0'='Alive'))

```

The code above recodes the integer values of the raw data into a factor with two levels: "Alive" and "Died".

### Check missing values

```{r missing, echo=F}
LOS %>% 
  map(is.na) %>% 
  map(sum)

```

There are no counts of missing values (NA).

### Check for error values

```{r error}
summary(LOS)

```

The summary function shows some of the summary statistics of the dataset. Here we can confirm there are no missing values (which would be counted above). In addition, there appears to be no obvious extreme or error values (such as negative values for age or LOS).

## Save raw data 

As seen from the brief exploration of the dataset above, the data is extremely clean. An output of the final raw dataset is shown below of the first 10 rows of the data.

```{r raw_table}
LOS %>% 
  head(10) %>% 
  kable()

```

With no further manipulation or transformation, the data is saved as a csv file as '/RawData/Los_raw.csv'
```{r save_raw_data}
write_csv(LOS, here("RawData", "LOS_raw.csv"))
```

## Splitting data into test and training sets

```{r split_data}
set.seed(777)
testIndex <- createDataPartition(LOS$ID, p = 10/nrow(LOS), 
                                  list = FALSE, 
                                  times = 1)

```

Using the createDataPartition() function from the caret package, the ID column of the raw dataset is used as the index to split the dataset into test and training sets. The selected ID numbers are shown above to be split into the test dataset.

```{r split_data2}
LOS_test <- LOS[testIndex,]
LOS_train <- LOS[-testIndex,]

# Save a row for assessment marking
LOS_test_marker <- LOS_test[1,]
LOS_test <- LOS_test[2:nrow(LOS_test),]

```

The LOS dataset is split using the testIndex as shown above. One observation is removed from the test data to be used for assessment marking purposes. 

The test dataset has one row set aside for marking. The three data sets (test marker, test, training) are then saved in the 'Data' folder.

```{r save_tables}
# Save a row for assessment marking
LOS_test_marker <- LOS_test[1,]
LOS_test <- LOS_test[2:nrow(LOS_test),]

# Save test and train datasets as csv into 'Data' folder.
write_csv(LOS_train, here("Data", "LOS_train.csv"))
write_csv(LOS_test, here("Data", "LOS_test.csv"))
write_csv(LOS_test_marker, here("Data", "LOS_test_marker.csv"))
```

# Data capture tool (python)

#### Please see the jupyter notebook to see the Python source code and the functional data capture tool.

The data capture tool was created using Python within a jupyter notebook. The tool shows the source code of data preparation and uses ipython widgets to create interactive widgets for data entry. By using python, each row of data can be added dynamically by using a submit button, and the collected data table is updated automatically. This is a better user experience compared to iterating through cell blocks for each row of data entered. The collected data is saved as a csv file in the 'RawData' folder.

# Building Data dictionary in R

```{r dict_setup, message=F, results=F}
CollectedData=read_csv(here("RawData", "CollectedDataFinal.csv"))

```
```{r dict_setup2}
glimpse(CollectedData)
```

The Data collected from the collection tool is loaded into R. As shown, there is a consent column which is added during the data collection in the tool.

## Create Linker dataframe
```{r dict_linker}
variable_description <- c(
  'Integer value representing patient number - should be unique and allows refer
  encing rows to the original raw data.',
  'A factor consisting of a string that represents a hospital or organisation 
  e.g. "Trust1"',
  'Integer value representing age of the patient.',
  'Integer value representing the days a patient was in hospital.',
  'A factor consisting of a string that is either "Alive" or "Died", 
  representing the status of the patient at the end of their hospital stay.',
  'A boolean value representing the consent from the end-user to process and 
  share the data collected with the data capture tool.'
)

variable_type <- c(0,1,0,0,1,1)

linker<-build_linker(CollectedData, variable_description, variable_type)

```

A linker dataframe is created using variable_description (string vector describing each column) and variable_type (integer vector, 0 for quantitative and 1 for fixed values). This dataframe will then be used to create a data dictionary

## Build dictionary
```{r dict_build, results=F}
# Build dictionary
dictionary <- build_dict(my.data = CollectedData, linker = linker)

```
A dictionary is build using build_dict(), using the collected data and the linker dataframe. Notes are currently left empty to be manually filled below.

```{r dict_notes}
# Add notes
dictionary[3,4]<-'Alive: The patient survived the hospital admission.'
dictionary[4,4]<-'Died: The patient died during hospital admission.'
dictionary[7,4]<-'Trust3: Name of hospital/organisation that admitted patient.'
dictionary[8,4]<-'Trust9: Name of hospital/organisation that admitted patient.'
dictionary[9,4]<-'Trust6: Name of hospital/organisation that admitted patient.'
dictionary[10,4]<-'Trust2: Name of hospital/organisation that admitted patient.'
dictionary[11,4]<-'Trust4: Name of hospital/organisation that admitted patient.'
dictionary[12,4]<-'Trust5: Name of hospital/organisation that admitted patient.'
dictionary[13,4]<-'Trust7: Name of hospital/organisation that admitted patient.'
dictionary[14,4]<-'Trust10: Name of hospital/organisation that admitted patient.'
```

## Save dictionary
```{r dict_save}
write_csv(dictionary, here("RawData", "CollectedData_DataDictionary.csv"))
```

The dictionary saved, and can be re-used for future data collection.

## Append dictionary onto dataset
```{r dict_append}
# Main string description
main_string <- "This data describes the hospital length of stay (LOS) and outcome
(death/survived) data from the *NHSRdatasets* package collected by the data
capture tool."

complete_CollectedData <- incorporate_attr(my.data = CollectedData, 
                                           data.dictionary = dictionary,
                                           main_string = main_string)

# Change the author name
attributes(complete_CollectedData)$author[1]<-"B213753"

```

The data dictionary is now appended onto the attributes of the collected dataset using incorporate_attr(), along with a main description and the author name. The attributes can be seen above.

## Save completed dataset as R dataset file.
```{r dict_saveRDS}
save_it(complete_CollectedData, here("RawData", "complete_CollectedData"))
        
```

